---
tags:
  - arquitetura_software
  - engenharia_de_dados
---
# Apache Airflow

Considere o uso de [Apache Airflow](https://airflow.apache.org/) se sua organização tiver pipelines de dados complexos com muitas dependências de fluxo de trabalho. É uma ótima ferramenta para agendar e orquestrar trabalhos de dados em lote executados em várias tecnologias em pipelines de dados de ponta a ponta. 

O Airflow fornece operadores prontos para uso para interagir com ferramentas populares de ETL e permite que os desenvolvedores escrevam código personalizado para acionar qualquer ferramenta com a qual o Python interaja.

Versões em Cloud:

- AWS - Amazon Managed Workflows for Apache Airflow é uma versão já hospedada do Airflow.

# Casos de uso

- [[Submissão de jobs PySpark]]