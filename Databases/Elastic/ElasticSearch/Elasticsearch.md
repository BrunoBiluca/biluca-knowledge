---
tags:
  - banco_de_dados
  - engenharia_de_dados
---
#banco_de_dados 

# Elasticsearch

# IntroduÃ§Ã£o

## O que Ã©? E para que serve? O que come?

Elasticsearch Ã© uma das ferramentas mais em alta nos Ãºltimos tempos. Ã‰ um **mecanismo de busca e anÃ¡lise distribuÃ­da em Json**. 

Projetos que necessitam de pesquisas rÃ¡pidas ou grande abrangÃªncia de consultas, agregaÃ§Ãµes e mÃ©tricas em tempo real tem no Elasticsearch uma Ã³tima das melhores ferramentas disponÃ­veis.

Junto ao Elasticsearch tambÃ©m Ã© possÃ­vel utilizar o Ã³timo** Kibana, um sistema de visualizaÃ§Ã£o e gerenciamento de dados**, altamente versÃ¡til que possibilita criar dashboards incrÃ­veis e completos, exibiÃ§Ã£o de dados por geolocalizaÃ§Ã£o, anÃ¡lise de logs e mÃ©tricas de serviÃ§os.

PorÃ©m como nem tudo sÃ£o flores o Elasticsearch Ã© um sistema pesado para manter, utilizar o Elasticsearch para uma grande quantidade de dados e um uso grande de queries pesadas pode requisitar uma infraestrutura poderosa e consequentemente uma muito cara ðŸ’°. Isso principalmente pelos requisitos de storage rÃ¡pido SSD e em grande quantidade e uma quantidade muito grande de RAM para armazenar sua tabela de indexaÃ§Ã£o, somado a um uso muito grande de CPU para grandes agregaÃ§Ãµes paralelas.

Para contornar esses problemas algumas medidas de otimizaÃ§Ãµes devem ser tomadas, vou apresentar abaixo algumas dicas que ao longo dos projetos que participei melhoraram muito a performance do sistema e nos fez economizar um trocado bem bom.

## Ferramentas da stack do Elastic

Ã‰ importante conhecer algumas ferramentas da stack do Elasticsearch para conseguir usufruir o melhor possÃ­vel de cada uma em seus casos de atuaÃ§Ãµes especÃ­ficos.

Todos as ferramentas abaixo sÃ£o gratÃºitas:

- Elasticsearch: entidade principal de qualquer stack Elastic, Ã© um mecanismo de busca e anÃ¡lise distribuÃ­da baseado em JSON
- Kibana: fiel companheiro do Elasticsearch o Kibana Ã© uma interface de usuÃ¡rio extensÃ­vel, Ã³tima para fazer anÃ¡lises e publicar Dashboards com os dados armazenados no ElasticSearch.
- Logstash: O Logstash Ã© um pipeline gratuito e aberto de processamento de dados do lado do servidor que faz a ingestÃ£o de dados de inÃºmeras fontes, transforma-os e envia-os para o seu "esconderijo" favorito.

# Infraestrutura

Uma coisa importante de entender a respeito do Elasticsearch Ã© a forma de utilizaÃ§Ã£o. Existem duas formas de utilizar o Elasticsearch:

- Single-node
- Cluster

O **single-node** Ã© uma instÃ¢ncia de Elasticsearch contida em uma Ãºnica mÃ¡quina ou VM, utilizada principalmente para desenvolvimento.

O modo **cluster** Ã© o mais recomendado para grandes massas de dados, assim podemos distribuir nossos dados por uma rede de mÃ¡quinas ou VMs e entÃ£o aproveitar de toda essa paralelizaÃ§Ã£o para escalar horizontalmente a aplicaÃ§Ã£o.

## CriaÃ§Ã£o do Elasticsearch local para desenvolvimento

Para a criaÃ§Ã£o do Elasticsearch local focado em desenvolvimento pode ser facilmente feito utilizando a versÃ£o **single-node**. 

Nessa versÃ£o todas as funcionalidades do Elasticsearch estÃ£o disponÃ­veis, porÃ©m elas estÃ£o limitadas a apenas uma mÃ¡quina sendo utilizada,
tambÃ©m nÃ£o hÃ¡ comunicaÃ§Ã£o entre os nÃ³s.

### Docker para execuÃ§Ã£o single-node do ElasticSearch
```yml
version: '2.2'
services:
Â  es01:
Â  Â  image: docker.elastic.co/elasticsearch/elasticsearch:7.11.1
Â  Â  container_name: es01
Â  Â  environment:
Â  Â  Â  - xpack.security.enabled=false
Â  Â  Â  - discovery.type=single-node
Â  Â  ulimits:
Â  Â  Â  memlock:
Â  Â  Â  Â  soft: -1
Â  Â  Â  Â  hard: -1
Â  Â  Â  nofile:
Â  Â  Â  Â  soft: 65536
Â  Â  Â  Â  hard: 65536
Â  Â  volumes:
Â  Â  Â  - data01:/usr/share/elasticsearch/data
Â  Â  ports:
Â  Â  Â  - 9200:9200
Â  Â  Â  - 9300:9300
  
Â  kibana:
Â  Â  image: docker.elastic.co/kibana/kibana:7.11.1
Â  Â  environment:
Â  Â  Â  - ELASTICSEARCH_HOSTS=http://es01:9200
Â  Â  ports:
Â  Â  Â  - 5601:5601
Â  Â  depends_on:
Â  Â  Â  - es01

volumes:
Â  data01:
Â  Â  driver: local
```

Utilizando o `docker-compose.yml` serÃ£o inicializados 2 serviÃ§os docker:

- es01: AplicaÃ§Ã£o do Elasticsearch no modo single-node
  - [http://localhost:9200]()
- kibana: AplicaÃ§Ã£o do Kibana com vÃ¡rias funcionalidades para mostrar informaÃ§Ãµes persistidas no Elasticsearch
  - [http://localhost:5601]()

## CriaÃ§Ã£o do Elasticsearch local modo cluster

### Docker para execuÃ§Ã£o cluster do ElasticSearch
```yml
version: '2.2'
services:
Â  es01:
Â  Â  image: docker.elastic.co/elasticsearch/elasticsearch:7.11.1
Â  Â  container_name: es01
Â  Â  environment:
Â  Â  Â  - node.name=es01
Â  Â  Â  - cluster.name=es-docker-cluster
Â  Â  Â  - discovery.seed_hosts=es02,es03
Â  Â  Â  - cluster.initial_master_nodes=es01,es02,es03
Â  Â  Â  - bootstrap.memory_lock=true
Â  Â  Â  - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
Â  Â  ulimits:
Â  Â  Â  memlock:
Â  Â  Â  Â  soft: -1
Â  Â  Â  Â  hard: -1
Â  Â  volumes:
Â  Â  Â  - data01:/usr/share/elasticsearch/data
Â  Â  ports:
Â  Â  Â  - 9200:9200
Â  Â  networks:
Â  Â  Â  - elastic
Â  es02:
Â  Â  image: docker.elastic.co/elasticsearch/elasticsearch:7.11.1
Â  Â  container_name: es02
Â  Â  environment:
Â  Â  Â  - node.name=es02
Â  Â  Â  - cluster.name=es-docker-cluster
Â  Â  Â  - discovery.seed_hosts=es01,es03
Â  Â  Â  - cluster.initial_master_nodes=es01,es02,es03
Â  Â  Â  - bootstrap.memory_lock=true
Â  Â  Â  - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
Â  Â  ulimits:
Â  Â  Â  memlock:
Â  Â  Â  Â  soft: -1
Â  Â  Â  Â  hard: -1
Â  Â  volumes:
Â  Â  Â  - data02:/usr/share/elasticsearch/data
Â  Â  networks:
Â  Â  Â  - elastic
Â  es03:
Â  Â  image: docker.elastic.co/elasticsearch/elasticsearch:7.11.1
Â  Â  container_name: es03
Â  Â  environment:
Â  Â  Â  - node.name=es03
Â  Â  Â  - cluster.name=es-docker-cluster
Â  Â  Â  - discovery.seed_hosts=es01,es02
Â  Â  Â  - cluster.initial_master_nodes=es01,es02,es03
Â  Â  Â  - bootstrap.memory_lock=true
Â  Â  Â  - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
Â  Â  ulimits:
Â  Â  Â  memlock:
Â  Â  Â  Â  soft: -1
Â  Â  Â  Â  hard: -1
Â  Â  volumes:
Â  Â  Â  - data03:/usr/share/elasticsearch/data
Â  Â  networks:
Â  Â  Â  - elastic
  
volumes:
Â  data01:
Â  Â  driver: local
Â  data02:
Â  Â  driver: local
Â  data03:
Â  Â  driver: local
  
networks:
Â  elastic:
Â  Â  driver: bridge
```

## Shards e Replicas

- Shards: sÃ£o os containers dos dados. Quando um documento Ã© indexado, o Elasticsearch verifica em qual shard esse documento serÃ¡ armazenado e entÃ£o ele Ã© persistido lÃ¡.

- RÃ©plicas: sÃ£o replicaÃ§Ãµes dos shards criados, rÃ©plicas **podem ser utilizadas para melhorar a performance de consultas e agregaÃ§Ãµes**, jÃ¡ que aumentam a parelelizaÃ§Ã£o a execuÃ§Ã£o dessas queries pelo cluster. Uma replica pode espelhar um shard Ã© sempre persistida em um datanode diferente. Outra vantagem do uso de rÃ©plicas Ã© a garantia da disponibilidade dos dados no seu sistema. A principal disvantagem de utilizar rÃ©plicas Ã© a quantidade de armazenamento necessÃ¡rio, dependendo da quantidade de dados armazenados no Elasticsearch, serÃ¡ necessÃ¡rio gastar o dobro ou mais.

# Mapeamento

O Mapeamento Ã© uma configuraÃ§Ã£o que Ã© passada apenas na criaÃ§Ã£o do **Index**, cada tipo de campo no Elasticsearch tem uma forma de armazenagem e de indexaÃ§Ã£o diferente.

Por padrÃ£o todo novo campo contido em um documento enviado para um index serÃ¡ indexado de acordo com a polÃ­tica padrÃ£o. Para alterar o comportamento padrÃ£o Ã© necessÃ¡rio fornecer um arquivo de mapeamento com a configuraÃ§Ã£o desejada.

## Principais tipos de campos

- Keyword
- Text
- Long
- Date

No caso de ter uma lista o campo de lista Ã© mapeado como o tipo do primeiro elemento da lista, e nÃ£o Ã© possÃ­vel criar uma lista com tipos diferentes de dados. Isso porque cada elemento da lista Ã© indexado individualmente, por esse fato deixar elementos em listas nÃ£o reduz a performances das consultas feitas ao Elasticsearch.

## ParÃ¢metros do mapeamento

Alguns dos parÃ¢metros mais utilizado para a criaÃ§Ã£o de mapeamento

- **coerce:** adicionar coerce no mapeamento de um campo Ã© uma tentativa de limpar o dado quando este nÃ£o vier no tipo mapeado do campo.
	-  Strings will be coerced to numbers.
	- Floating points will be truncated for integer values.
- **eager_global_ordinals:** cada vez que o shard Ã© atualizado esses campos serÃ£o carregados antes. Isso pode ajudar muito na performance de queries no formato **Per-Document Basis** como quando utilizamos ```terms``` em campos como ```keyword```. Dessa forma passamos o **custo de performance na hora do re-index** no lugar de fazer o mesmo processo na hora que a query Ã© requisitada.
- **ignore_malformed:** garante o formato necessÃ¡rio para o campo no quando o campo estÃ¡ num formato nÃ£o de acordo com o mapeamento
- **enabled:** Podemos desativar a indexaÃ§Ã£o de um campo, o campo pode ser recuperado, mas perde a funcionalidade de ser pesquisado
  - Muito Ãºtil para diminuir o uso de storage e o uso de RAM consumida

## Exemplo de json de mapeamento

```json
"properties": {
    "title": { 
        "type": "text", 
    },  
    "author": {
        "type": "keyword",
        "eager_global_ordinals": true
    },
    "categories": {"type": "keyword"},
    "content": { "type": "text" }, 
    "createdAt": { "type": "date" },     
    "comments": { 
        "type": "object",
        "enabled": false
    }
}
```

Utilizando esse mapeamento de dados podemos ver uma melhoria muito grande no storage do Elasticsearch

![DiferenÃ§a do mapeamento em relaÃ§Ã£o a storage](storage_diff_mapping.PNG)

## Routing

Um tÃ³pico importante de tratar sobre Mapeamento Ã© a forma que o seu dados Ã© armazenado no Elasticsearch, principalmente se vocÃª tem vÃ¡rios nÃ³s com vÃ¡rios shards e rÃ©plicas.

Por padrÃ£o o Elasticsearch utiliza a seguinte conta para indexar os seus dados:

`shard_num = hash(_routing) % num_primary_shards`

Onde o `_routing` Ã© o `_id` do documento.

Fazendo dessa forma vocÃª permite que os seus documentos estejam melhores distribuÃ­dos por todos os seus datanodes, otimizando o storage.

PorÃ©m a utilizaÃ§Ã£o dessa estratÃ©gia para agregaÃ§Ãµes mais complexas pode representar uma perda de performance muito grande. Isso ocorre porque os dados deverÃ£o ser agrupados em cada shard para entÃ£o serem agrupados no datanode e finalmente agrupados em nÃ­vel do Elasticsearch.

Utilizando uma rota customizada podemos garantir que todos os dados necessÃ¡rios para aquela agregaÃ§Ã£o esteja em um mesmo shard melhorando a performance.

Uma **boa estratÃ©gia** para garantir o roteamente Ã© utilizar campos que sempre serÃ£o utilizados nos **filtros gerais** das agregaÃ§Ãµes. Campos muito utilizados para isso sÃ£o campos referentes a datas ou ids de clientes, jÃ¡ que a agregaÃ§Ã£o sempre serÃ¡ feita utilizando esse filtro.

Para garantir que a rota deva ser enviada na inserÃ§Ã£o dos dados Ã© necessÃ¡rio apenas criar um mapeamento utilizando:

```json
{
  "mappings": {
    "_routing": {
      "required": true 
    }
  }
}
```

O insert de documentos deve ser feito entÃ£o da seguinte maneira:

```json
{
  "_routing": "CategoriaA_2021",
  "title": "Pesquisa elÃ¡stica",  
  "author": "Senhor elÃ¡stico",
  "content": "Era uma vez um menino que conseguia fazer contorcionismo", 
  "categories": ["CategoriaA"],
  "createdAt": "2021-03-04",     
  "comments": [
    "BÃ£o demais da conta",
    "5 estrelas",
    "Curti muito nÃ£o"
  ]
}
```

Dessa forma eu garanto que todos os dados do Autor referentes ao ano de 2021 estÃ£o no mesmo shard e agregaÃ§Ãµes que utilizem dessa informaÃ§Ã£o serÃ£o feitas mais facilmente. Por exemplo analisar todos os comentÃ¡rios em busca de comentÃ¡rios positivos de todos os livros referentes a categoria CategoriaA no ano de 2021.

# IngestÃ£o dos dados

## IngestÃ£o direta

- IngestÃ£o documento a documento

Para inserir documentos no Elasticsearch Ã© necessÃ¡rio apenas enviar no body da requisiÃ§Ã£o o documento no formato Json que se deseja. Caso o documento tenha algum campo nÃ£o existente no mapeamento este serÃ¡ mapeado de acordo com o motor do Elasticsearch. 

- IngestÃ£o em bulk

Outra forma de enviar documentos para o Elasticsearch Ã© enviar todos os documentos em apenas uma Ãºnica chamada, fazendo entÃ£o uma opÃ§Ã£o de Bulk.

Quando se utiliza a ingestÃ£o por bulk Ã© necessÃ¡rio enviar dois objetos para cada documento ingerido, o objeto do Ã­ndice e o prÃ³prio objeto do documento.

- IngestÃ£o utilizando Apache Spark

Quando estamos utilizando o Apache Spark Ã© necessÃ¡rio utilizar um conector especÃ­fico do Haddop e Elasticsearch para fazer o envio das informaÃ§Ãµes.

Nesse caso as informaÃ§Ãµes sÃ£o enviadas de forma paralela para o Elasticsearch. Uma consideraÃ§Ã£o a se fazer Ã©, no caso de uma grande massa de dados ser enviada para o Elasticsearch o processo de indexaÃ§Ã£o desses dados por ser pesada o suficiente para os recursos disponÃ­veis no cluster Elasticsearch como CPU serem totalmente utilizados, e isso pode deixar o cluster do Elasticsearch sobrecarregado para executar agregaÃ§Ãµes.

---

### DemonstraÃ§Ã£o de performance

```python
from elasticsearch import Elasticsearch
es = Elasticsearch([{"host": "localhost", "port": 9200}])

# Envio individual de objetos
for i in range(10000):
	res = es.index(index, body=random_object())

# Envio em buld dos objetos
body = []
for i in range(10000):
	body.append({'index': {}})
	body.append(random_object())

res = es.bulk(body, index=index, doc_type='_doc')
```

Podemos notar uma diferenÃ§a muito grande no tempo de ingestÃ£o entre os tipos de ingestÃ£o simples e no modelo bulk. Esse valores foram feitos utilizando o ambiente local.

![DiferenÃ§a entre os tipos de ingestÃ£o de dados](insert_diff.PNG)

- Insert simples: 589s
- Bulk: 36s

## IngestÃ£o utilizando pipelines

Pipelines podem ser utilizados para corrigir ou modificar algum documento que estÃ¡ sendo inserido no Elasticsearch, dessa forma garantimos uma sanidade dos dados em um Ã­ndice ou podemos tambÃ©m em tempo de inserÃ§Ã£o criar novos dados a partir do documento enviado a fim de melhorar performance em consultas ou agregaÃ§Ãµes ou removendo dados que podem ser ignorados quando utilizados no Elasticsearch.

Outra vantagem de utilizar Pipelines Ã© poder compartilhar pipelines entre vÃ¡rios indexes possibilitando assim uma consistÃªncia maior dos dados.

Um pipeline Ã© constituÃ­do como uma lista de `processors`.

Principais processors utilizados:

- `set`: atribuir um valor ao campo, pode ser um valor estÃ¡tico ou uma valor do documento a ser injetado
- `append`: adiciona elementos a um array jÃ¡ existem em um documento
- `json`: converte uma string json para um json estruturado
  - Muito utilizado quando a sua fonte de dados sÃ³ consegue enviar strings para o Elasticsearch, como Ã© o caso do conector de Hadoop quando enviamos um DataFrame para persistir.
- `script`: podemos utilizar de uma linguagem de script (por padrÃ£o painless) para formatarmos os dados
- `pipeline`: podemos chamar um prÃ³ximo pipeline de execuÃ§Ã£o

```json
// "routing_processor"
{
	"description": "Pipeline responsÃ¡vel por garantir o campo de rotas do indexes baseados em livros",
	"processors": [
		{
			"set": {
				"field": "_routing",
				"value": "{{author}}_{{releaseYear}}"
			}
		},
		{
			"script": {
				"source": """
					ctx.comment_count = ctx.comments.length
				"""
			}
		}
	]
}
```

# Queries

## Search

Search Ã© provavelmente o recurso mais utilizado do Elasticsearch, com esse endpoint Ã© possÃ­vel fazer qualquer tipo de consultada, agregaÃ§Ã£o ou mÃ©trica com os dados armazenados.

### Exemplo de Search

```json
GET test-index/_search
{
  "size": 0, 
  "aggs": {
    "categories": {
      "terms": {
        "field": "categories",
        "size": 10000
      }
    }
  }
}
```

## MSearch

Uma alternativa ao Search para quando precisamos de utilizar da paralelizaÃ§Ã£o podemos enviar mÃºltiplas queries na mesma requisiÃ§Ã£o.

### Exemplo de MSearch

```json
GET test-index/_msearch
{"index": "test-index"}
{
  "size": 0, 
  "bool": {"must": [{"terms": {"categories": "Categoria XYZ"}}]},
  "aggs": {
    "categoria_count": {
      "value_count": {"field": ""}
    }
  }
}
{"index": "test-index"}
{
  "size": 0, 
  "bool": {"must": [{"terms": {"categories": "Categoria IJK"}}]},
  "aggs": {
    "categoria_count": {
      "value_count": {"field": ""}
    }
  }
}
```

Nesse caso temos duas queries sendo enviadas na mesma requisiÃ§Ã£o para o mesmo index, nesse caso as queries serÃ£o executadas em paralelo pelo Elasticsearch e possivelmente serÃ£o resolvidas mais rÃ¡pido que o mesmo exemplo utilizando o `query`.

## Boolean query

A Boolean query Ã© um dos recursos mais utilizados na criaÃ§Ã£o de queries no Elasticsearch, utilizamos uma query booleana para combinar vÃ¡rias clÃ¡usulas montando assim consultas mais complexas>

Os tipos de ocorrÃªncias possÃ­veis dentro de uma Boolean query sÃ£o:

- `must`: A clÃ¡usula que deve aparecer em um documento e contribui para aumentar o score desse documento.
- `filter`: A clÃ¡usula que deve aparecer em um documento, porÃ©m diferente do `must` nÃ£o contribui para o score do documento.
- `should`: A clÃ¡sula que pode aparecer em um documento.
  - Similar ao `OR` do SQL
  - Pode ser configurada com o campo `minimum_should_match` para determinar o nÃºmero mÃ­nimo de clÃ¡usulas atendidas para retornar `true` na query
- `must_not`: A clÃ¡usula que nÃ£o deve aparecer em um documento, esse documento entÃ£o passa a ser ignorado na consulta

### Exemplo de uma Boolean query

```json
{
  "query": {
    "bool" : {
      "must" : {
        "term" : { "title" : "Bruno" }
      },
      "filter": {
        "terms" : { "categories" : ["categoria 1", "categoria 2"] }
      },
      "must_not" : {
        "range" : {
          "createdAt" : { "gte" : "2020-01"}
        }
      },
      "should" : [
        { "terms" : { "comment" : "alegria" } },
        { "terms" : { "comment" : "felicidade" } }
      ],
      "minimum_should_match" : 1
    }
  }
}
```

## AgregaÃ§Ãµes

AgregaÃ§Ãµes no Elasticsearch sÃ£o formas de vocÃª resumir os seus dados em mÃ©tricas, estatÃ­sticas e qualquer outro tipo de anÃ¡lise.

Elas sÃ£o divididas em 3 tipos:

- Metric: agregaÃ§Ãµes de cÃ¡lculo de mÃ©tricas
  - Cardinality
  - Sum
  - Value Count
- Bucket: agregaÃ§Ãµes de agrupamento de documentos
  - Terms aggregations
- Pipeline: agregaÃ§Ãµes que utilizam outras agregaÃ§Ãµes como input no lugar de documentos

> [!tip] Melhoria de performance
> Uma coisa para ter atenÃ§Ã£o na hora de utilizar agregaÃ§Ãµes Ã© garantir que a varredura de itens serÃ¡ a menor possÃ­vel dentro do Elasticsearch. Qualquer filtro dentro da query pode melhorar muito a performance de uma agregaÃ§Ã£o.

Exemplo de query utilizando um filtro geral, serÃ¡ executado antes dos filtros de agregaÃ§Ãµes:

```json
// AgregaÃ§Ã£o geral
{
  "size": 0, 
  "query": {"bool": {"must": [{"terms": { "categories": ["A"]}}]}},
  "aggs": {"count": { "value_count": { "field": ""}}
}
```

Exemplo de query utilizando filtros nas aggregaÃ§Ãµes

```json
// AgregaÃ§Ã£o separada (por agregregaÃ§Ã£o)
{
  "size": 0, 
  "aggs": {
    "filter": {
        "bool": {"must": [{"terms": { "categories": ["A"]}}]}      
    },
    "aggs": {"count": { "value_count": { "field": ""}}
  }
}
```

Outra questÃ£o Ã© que as agregaÃ§Ãµes em uma query sÃ£o resolvidas de forma sequencial, nÃ£o sendo utilizado assim a paralelizaÃ§Ã£o do cluster.

> [!tip] EstratÃ©gia de paralelizaÃ§Ã£o de agregaÃ§Ãµes
> Uma boa estratÃ©gia pode ser quebrar as agregaÃ§Ãµes em vÃ¡rias queries e enviar essas queries todas de uma vez utilizando da api do `msearch`.

```json
// AgregaÃ§Ã£o por msearch
{"index": "test-index"}
{
  "size": 0, 
  "query": {"bool": {"must": [{"terms": { "categories": ["A"]}}]}},
  "aggs": {"count": { "value_count": { "field": ""}}
}
```

Fazendo o exemplo das categorias temos o seguinte resultado dos tempos das queries:

![](query_diff.PNG)

Nesse caso como estamos trabalhando com um Ãºnico nÃ³ do ElasticSearch o msearch se mostrou mais lento que os demais, porÃ©m em um cluster com vÃ¡rios nÃ³s, isso provavelmente nÃ£o seria assim.
## Gerenciamento do ElasticSearch

O prÃ³prio Elasticsearch apresenta vÃ¡rias queries que podem ser utilizadas para o seu gerenciamento, entre elas algumas das mais utilizadas seguem abaixo. 

- **index**/_cache/clear
  - POST
  - Query para resetar a cache de request para um Ã­ndice especÃ­fico
- /_cat/shards
  - POST
- /_cat/allocation
  - POST

Utilizar esse tipo de query pode ser interessante para criar sistemas de genreciamento automatizados no Kibana, para monitoramento personalizado do cluster de Elasticsearch.

# ReferÃªncias

- DocumentaÃ§Ã£o a respeito do mapeamento
	- [Mapeamento explÃ­cito](https://www.elastic.co/guide/en/elasticsearch/reference/7.11//explicit-mapping.html)
	- [Mapeamento de arrays](https://www.elastic.co/guide/en/elasticsearch/reference/7.11//array.html)
	- [Text](https://www.elastic.co/guide/en/elasticsearch/reference/7.11//text.html)
	- [Coerce](https://www.elastic.co/guide/en/elasticsearch/reference/7.11//coerce.html)
	- [Eager global ordinals](https://www.elastic.co/guide/en/elasticsearch/reference/7.11//eager-global-ordinals.html#eager-global-ordinals)
	- [Ignore Malformed](https://www.elastic.co/guide/en/elasticsearch/reference/7.11//ignore-malformed.html)
	- [Enabled](https://www.elastic.co/guide/en/elasticsearch/reference/7.11//enabled.html)
- Documenta relacionada a queries
	- [Boolean query](https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-bool-query.html)
	- [AgregaÃ§Ãµes](https://www.elastic.co/guide/en/elasticsearch/reference/current/search-aggregations.html)
	- [Cardinality](https://www.elastic.co/guide/en/elasticsearch/reference/current/search-aggregations-metrics-cardinality-aggregation.html)
	- [Terms Aggregation](https://www.elastic.co/guide/en/elasticsearch/reference/current/search-aggregations-bucket-terms-aggregation.html)