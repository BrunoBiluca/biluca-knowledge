# MapReduce

O Hadoop MapReduce é um modelo de programação projetado para processar grandes volumes de dados em paralelo, dividindo o trabalho em um conjunto de tarefas independentes. Ele consegue isso movendo a computação para perto dos dados, onde cada máquina tem um processo rodando uma parte do código de programação.